#### Divergences

##### Integral probability metrics

> Sriperumbudur, B.K., Fukumizu, K., Gretton, A., Scholkopf, B., & Lanckriet, G.R. (2009). On integral probability metrics, Ï†-divergences and binary classification. *arXiv: Information Theory*.

Suppose on measurable space $(\Omega, \F)$ there are two probability measures $P, Q$.

Suppose $\F \subseteq \L(\Omega \to \R)$ is a set of real-valued bounded measurable functions on $\Omega$.

Define the **integral probability metric** (IPM) $D_\F(P \Vert Q)$ between $P, Q$ as
$$
D_\F (P \Vert Q) := \sup_{f \in \F} \abs{\int_{\Omega} f(\omega) \dd P(\omega) - \int_{\Omega} f(\omega) \dd Q(\omega)}
$$

##### f-divergence

> https://en.wikipedia.org/wiki/F-divergence

Suppose on measurable space $(\Omega, \F)$ there are two probability measures $P, Q$. And that $P \ll Q$.

By **Radon-Nikodym theorem**, there exists a unique $\dd P / \dd Q \in L(\Omega \to [0, \infty])$ derivative density.

Suppose $f: [0, \infty] \to (-\infty, +\infty]$ is a convex (smile) function. $f(0, \infty) \subset \R$. And $f(1) = 0$.

Define the $f$-divergence $D_f$ between distributions as following.
$$
D_f(P \Vert Q):= \int_\Omega f\p{\frac{\dd P}{ \dd Q}} \dd Q
$$

- By Jensen's inequality, all $f$-divergences are non-negative.
  $$
  D_f(P \Vert Q) = E_Q\s{f\p{\frac{\dd P}{\dd Q}}} \ge  f\p{E_Q \s{\frac{\dd P}{\dd Q}}} = f(1) = 0
  $$

Suppose $(\Omega, \F, \mu)$ is a **reference measure space**. And we have **density** $P = p \dd \mu$ and $Q = q \dd \mu$. We also write
$$
D_f(p \Vert q) := \int_{\Omega} f\p{\frac{p(x)}{q(x)}} q(x) \dd \mu(x)
$$

- The two definitions are equivalent.

Suppose $X, Y$ are two random variables to the same space $(\Omega, \F)$. We write $D_f(X \Vert Y) := D_f(P_X \Vert P_Y)$.

##### KL-divergence

The KL-divergence is a special $f$-divergence.

$f(x) = x\ln (x)$ gives the KL-divergence, and $g(x) = -\ln(x)$ gives the inverse KL-divergence.
$$
D_{\mathup{KL}}(p \Vert q) = \int p(x) \ln \frac{p(x)}{q(x)} \dd \mu(x) = - \int \ln \frac{q(x)}{p(x)} p(x) \dd \mu (x) = D_{-\mathup{KL}}(q \Vert p)
$$
Suppose $p_*(x)$ is a **data density** on $\Omega$, and $p_\theta(x)$ is a density generated by a statistical model.

- $\d{p_*(x)}{p_\theta(x)}$ is known as the **forward KL**.
  - Minimizing the forward KL is equivalent to maximizing log likelihood. Since
  $$
  \d{p_*}{p_\theta} = \int p_*(x) \log \frac{p_*(x)}{p_\theta(x)} \dd x = -H(p_*) - \int p_*(x) \log p_\theta(x) \dd x
  $$
- $\d{p_\theta(x)}{p_*(x)}$ is known as the **backward KL**.
  - Minimizing the backward KL is known to let $p_\theta$ focusing on a particular mode of $p$.
  - Suppose we know $p_*(x)$ is of the form $p_*(x) = e^{-U(x)} / Z$. Then for $X \sim p_\theta(x)$,
  $$
  \d{p_\theta}{p_*} = E\s{\log p_\theta(X)} + E [U(X)] + \log Z
  $$
    - Optimizing the backward KL can be done with unnormalized density $p_*$.

##### Log-sum inequality

Suppose $(a_k)_{k \in I}$ and $(b_k)_{k \in I}$ are nonnegative real numbers. Suppose $I$ is countable.

Suppose $\sum_{k \in I} a_k = a \in (0, \infty)$ and $\sum_{k \in I} b_k = b \in (0, \infty)$. Then
$$
\sum_{k \in I} a_k \log \frac{a_k}{b_k} \ge a \log \frac{a} {b}
$$
Define $p_k = a_k / a$ and $q_k = b_k / b$. And its equivalent to $\d{p}{q} \ge 0$.



